#!/bin/bash


# Required env. variables:
# - DWH_USER
# - DWH_SERVER_NAME
# - DWH_SERVICE_ACCOUNT
# - DWH_SERVER_ZONE
# - BQ_STAGING_DATASET
# - BQ_DWH_DATASET


# Check necessary variables are set.
if [ -z ${DWH_USER} ]; then 
  echo "DWH_USER variable not set.";
  exit 1
elif [ -z ${DWH_SERVER_NAME} ]; then
  echo "DWH_SERVER_NAME variable not set.";
  exit 1
elif [ -z ${DWH_SERVICE_ACCOUNT} ]; then
  echo "DWH_SERVICE_ACCOUNT variable not set.";
  exit 1
elif [ -z ${DWH_SERVER_ZONE} ]; then
  echo "DWH_SERVER_ZONE variable not set.";
  exit 1
elif [ -z ${DWH_KEYFILE} ]; then
  echo "DWH_KEYFILE variable not set.";
  exit 1
elif [ -z ${BQ_STAGING_DATASET} ]; then
  echo "BQ_STAGING_DATASET variable not set.";
  exit 1
elif [ -z ${BQ_DWH_DATASET} ]; then
  echo "BQ_DWH_DATASET variable not set.";
  exit 1
elif [ -z ${AIRFLOW_USERNAME} ]; then
  echo "BQ_DWH_DATASET variable not set.";
  exit 1
elif [ -z ${AIRFLOW_PW} ]; then
  echo "BQ_DWH_DATASET variable not set.";
  exit 1
fi

# Create GCP compute instance for running airflow.
gcloud compute instances create ${DWH_SERVER_NAME} \
  --zone ${DWH_SERVER_ZONE}\
  --image ubuntu-2004-focal-v20210129\
  --image-project ubuntu-os-cloud\
  --tags http-server,airflow\
  --service-account ${DWH_SERVICE_ACCOUNT}
  #--metadata-from-file startup-script=../scripts/remote_setup.sh \


# Allowing http traffic to instance for access to airflow webinterface. 
# I would normally do additional work here (e.g. implement access over https 
# only, restrict access to certain IP range only, etc.)
gcloud compute firewall-rules create http-firewall --allow tcp:80,tcp:443 --target-tags http-server

# Write remote required values to env
cat > env.sh <<EOL
export AIRFLOW_USERNAME="${AIRFLOW_USERNAME}"
export AIRFLOW_PW="${AIRFLOW_PW}"
EOL

upload_keyfile() {
  # Sleep is necessary here as it takes some time before we can SSH into server.
  sleep 30
  gcloud compute scp ${DWH_KEYFILE} ${DWH_USER}@${DWH_SERVER_NAME}:keyfile.json
  gcloud compute scp  ../configs/nginx.conf ${DWH_USER}@${DWH_SERVER_NAME}:nginx.conf
  gcloud compute scp  ../scripts/remote_setup.sh ${DWH_USER}@${DWH_SERVER_NAME}:
  gcloud compute scp  env.sh ${DWH_USER}@${DWH_SERVER_NAME}:
  rm env.sh
}
# Move sensitive files to remote with retry if server is not ready yet.
# Rerun command if it fails at first.
upload_keyfile  || upload_keyfile || upload_keyfile

# Create BQ datasets
bq mk ${BQ_STAGING_DATASET}
bq mk ${BQ_DWH_DATASET}

gcloud compute ssh --zone ${DWH_SERVER_ZONE} ${DWH_USER}@${DWH_SERVER_NAME} < ../scripts/remote_setup.sh
